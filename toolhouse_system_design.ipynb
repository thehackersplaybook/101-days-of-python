{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolhouse and OpenAI Integration for System Design and Reporting\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "## Description:\n",
    "\n",
    "This app demonstrates the integration of OpenAI's language models with Toolhouse's system design and utility tools. It generates detailed reports, executes commands, and emails results based on user inputs, specifically focusing on system design topics. The app is designed for use in Jupyter notebooks, automating tasks like generating code, system design documentation, and sending email reports. It is highly customizable and uses environment variables for secure API key management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installing Python Dependencies\n",
    "\n",
    "This script ensures that the necessary Python dependencies are installed and the required environment variables (API keys) are set up correctly before running the program.\n",
    "\n",
    "---\n",
    "\n",
    "#### Imports:\n",
    "\n",
    "- `from IPython.display import clear_output:`  \n",
    "  This function is used to clear the output of the Jupyter notebook. It helps remove clutter from previous outputs and keeps the notebook clean.\n",
    "\n",
    "- `from dotenv import load_dotenv:`  \n",
    "  This function loads environment variables from a `.env` file into the environment. It ensures sensitive information, like API keys, is kept secure and not hardcoded in the source code.\n",
    "\n",
    "- `import os:`  \n",
    "  The `os` module allows interaction with the operating system. It is used to access environment variables, manage file paths, and execute system commands.\n",
    "  \n",
    "  ---\n",
    "\n",
    "#### Variables:\n",
    "\n",
    "- `requirements_installed = False:`  \n",
    "  A flag to track whether the necessary Python packages have been installed. This avoids redundant installations.\n",
    "\n",
    "- `max_retries = 3` and `retries = 0:`  \n",
    "  These variables manage the retry logic for installing requirements. If the installation fails, it will retry up to a maximum of three times.\n",
    "\n",
    "- `REQUIRED_ENV_VARS` = [\"OPENAI_API_KEY\", \"TOOLHOUSE_API_KEY\"]:  \n",
    "\n",
    "  A list that contains the names of the environment variables (API keys) required for authenticating with OpenAI and Toolhouse.\n",
    "\n",
    "---\n",
    "\n",
    "#### install_requirements() :\n",
    "\n",
    "  - This function installs the necessary dependencies if they have not been installed already. It checks if `requirements_installed` is `False` and proceeds to install the dependencies using the command `pip install -r requirements.txt`. If the installation fails, it retries up to `max_retries` times. After exhausting all retries, it exits the program.\n",
    "\n",
    "  ---\n",
    "\n",
    "#### setup_env() :\n",
    "\n",
    "This function validates that the required environment variables (API keys) are set.  \n",
    "\n",
    "  - Inside this function, `check_env()` is defined to check if an environment variable is present. It uses `os.getenv()` to fetch the value of each environment variable. If the variable is not found, the program will print a message and exit. If the variable is found, it prints a confirmation message.\n",
    "  - `load_dotenv(override=True)` loads the environment variables from the `.env` file into the environment, ensuring the program can access them.\n",
    "  - The function then iterates over the required environment variables (`REQUIRED_ENV_VARS`) and checks if each is set using `check_env()`.\n",
    "\n",
    "---\n",
    "#### Final Execution:\n",
    "\n",
    "  - `install_requirements()` is called to ensure the required dependencies are installed.\n",
    "  - `clear_output()` clears the output of the Jupyter cell to provide a clean workspace.\n",
    "  - `setup_env()` is called to ensure that the environment variables are correctly loaded and validated.\n",
    "\n",
    "- Finally, it prints \"ðŸš€ Setup complete. Continue to the next cell.\" to notify the user that the setup has been completed successfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = [\"OPENAI_API_KEY\", \"TOOLHOUSE_API_KEY\"]\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "clear_output()\n",
    "setup_env()\n",
    "print(\"ðŸš€ Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting Up OpenAI and Toolhouse Integration\n",
    "\n",
    "This script sets up the environment and integrates OpenAI and Toolhouse for generating and executing code based on user input.\n",
    "\n",
    "---\n",
    "\n",
    "#### Imports:\n",
    "\n",
    "- `import os:`  \n",
    "  The `os` module is used to access environment variables, which store sensitive data like API keys.\n",
    "\n",
    "- `from openai import OpenAI:`  \n",
    "  This imports the OpenAI module that allows us to interact with OpenAI's API and use its language models.\n",
    "\n",
    "- `from toolhouse import Toolhouse:`  \n",
    "  This imports the Toolhouse library, which enables the integration of system design and utility tools with OpenAI.\n",
    "\n",
    "---\n",
    "\n",
    "#### API Key Setup:\n",
    "\n",
    "- `OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\"):`  \n",
    "  The OpenAI API key is retrieved from the environment variables using `os.getenv()`. This key is required to authenticate and use OpenAIâ€™s models.\n",
    "\n",
    "- `TOOLHOUSE_API_KEY = os.getenv(\"TOOLHOUSE_API_KEY\"):`  \n",
    "  Similarly, the Toolhouse API key is retrieved to authenticate Toolhouse API usage.\n",
    "\n",
    "---\n",
    "\n",
    "#### Initialize OpenAI and Toolhouse Clients:\n",
    "\n",
    "- `client = OpenAI(api_key=OPENAI_API_KEY):`  \n",
    "  An instance of the OpenAI client is created using the API key retrieved earlier.\n",
    "\n",
    "- `th = Toolhouse(api_key=TOOLHOUSE_API_KEY, provider=\"openai\"):`  \n",
    "  An instance of the Toolhouse client is created, specifying OpenAI as the provider of tools for system design tasks.\n",
    "\n",
    "---\n",
    "\n",
    "#### Model Selection:\n",
    "\n",
    "- `MODEL = \"gpt-4o-mini\":`  \n",
    "  The GPT-4 model variant (`gpt-4o-mini`) is chosen for generating completions. This model is suitable for generating code, responses, and handling complex queries.\n",
    "\n",
    "---\n",
    "\n",
    "#### Defining the User Input (Messages):\n",
    "\n",
    "- `messages = [{\"role\": \"user\", \"content\": \"Generate FizzBuzz code. Execute it to show me the results up to 10.\"}]`  \n",
    "  This defines the user input, where the user requests FizzBuzz code generation and execution for the numbers 1 to 10.\n",
    "\n",
    "---\n",
    "\n",
    "#### First API Call (Generate Code):\n",
    "\n",
    "- `response = client.chat.completions.create(...)`  \n",
    "  This makes the first API call to OpenAIâ€™s `chat.completions.create()` method. It sends the userâ€™s message to the model and includes the available Toolhouse tools (via `th.get_tools()`), enabling the model to utilize these tools for enhanced functionality.\n",
    "\n",
    "---\n",
    "\n",
    "#### Running Toolhouse Tools:\n",
    "\n",
    "- `messages += th.run_tools(response):`  \n",
    "  Toolhouse tools are invoked based on the response received. This method runs the tools and appends any results back to the messages list.\n",
    "\n",
    "---\n",
    "\n",
    "#### Second API Call (Execute Tools and Get Final Output):\n",
    "\n",
    "- `response = client.chat.completions.create(...)`  \n",
    "  Another API call is made to OpenAI, but this time the `messages` list has been updated with the output from the tools. The system uses this updated list to generate the final response.\n",
    "\n",
    "---\n",
    "\n",
    "#### Output the Result:\n",
    "\n",
    "- `print(response.choices[0].message.content):`  \n",
    "  The content of the final response is printed, which includes the generated FizzBuzz code and its results.\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Points:\n",
    "\n",
    "- **Integration of OpenAI and Toolhouse:** Toolhouseâ€™s tools are used alongside OpenAIâ€™s model to execute system design tasks and generate responses based on user input.\n",
    "\n",
    "- **Execution of Generated Code:** The code generated by OpenAI can be executed and processed further through the integration with Toolhouse.\n",
    "\n",
    "- **Dynamic Interaction:** The flow is interactive, where the initial user input generates code, the tools execute it, and the result is sent back to the model for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: Just a basic use of Toolhouse x OpenAI\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from toolhouse import Toolhouse\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TOOLHOUSE_API_KEY = os.getenv(\"TOOLHOUSE_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "th = Toolhouse(api_key=TOOLHOUSE_API_KEY, provider=\"openai\")\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate FizzBuzz code.\"\n",
    "        \"Execute it to show me the results up to 10.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL, messages=messages, tools=th.get_tools()\n",
    ")\n",
    "\n",
    "messages += th.run_tools(response)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL, messages=messages, tools=th.get_tools()\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Integration of OpenAI with Toolhouse for System Design\n",
    "\n",
    "This code integrates OpenAI's language model with Toolhouse's system design tools, including the `thp-system-design-assistant`. It defines a function, `llm`, which assists in system design tasks by combining these tools and refining results iteratively.\n",
    "\n",
    "---\n",
    "\n",
    "### Setup:\n",
    "\n",
    "- The OpenAI and Toolhouse API keys are fetched from environment variables using `os.getenv()`, ensuring secure and dynamic access to the APIs.\n",
    "\n",
    "---\n",
    "\n",
    "### Messages:\n",
    "\n",
    "- The system and user messages are defined to form the prompt for the OpenAI model. These messages guide the interaction and specify the task to be performed.\n",
    "\n",
    "---\n",
    "\n",
    "### API Call:\n",
    "\n",
    "- An initial API call is made to OpenAI's API using the `client.chat.completions.create()` method. This includes the system design tools provided by Toolhouse.\n",
    "\n",
    "---\n",
    "\n",
    "### Tool Iteration:\n",
    "\n",
    "- If the response from OpenAI requires further processing or the use of tools, the function iterates and runs the necessary tools using the `th.run_tools()` method. This allows the model to refine its output through multiple tool invocations.\n",
    "\n",
    "---\n",
    "\n",
    "### Verbose/Intermediate Outputs:\n",
    "\n",
    "- The function supports printing intermediate results and final responses. This is helpful for debugging, tracking progress, and understanding how the model's output evolves with each tool iteration.\n",
    "\n",
    "---\n",
    "\n",
    "### Error Handling:\n",
    "\n",
    "- Errors encountered during the process are caught and printed with traceback, enabling easy debugging and tracking of issues that may arise.\n",
    "\n",
    "---\n",
    "\n",
    "### In Essence:\n",
    "\n",
    "- The function processes the user prompt, applies the system design tools iteratively, and returns the final result. It leverages OpenAI for natural language processing and Toolhouse for system design tasks, ensuring a seamless, dynamic, and efficient solution for system design assistance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: LLM with Toolhouse\n",
    "## Include the following tools in the Toolhouse bundle: thp-system-design-assistant\n",
    "## Sendgrid, Web Scraper, and Memory tools are included in this bundle.\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from toolhouse import Toolhouse\n",
    "import traceback\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TOOLHOUSE_API_KEY = os.getenv(\"TOOLHOUSE_API_KEY\")\n",
    "MAX_ITERS = 10\n",
    "th = Toolhouse(api_key=TOOLHOUSE_API_KEY, provider=\"openai\")\n",
    "openai = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "def llm(\n",
    "    prompt: str,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    system=\"You are a helpful AI assistant\",\n",
    "    intermediate_output=True,\n",
    "    verbose=True,\n",
    ") -> str:\n",
    "    \"\"\"Wrapper over Open AI LLM calls with Toolhouse Tools.\"\"\"\n",
    "    try:\n",
    "        if verbose:\n",
    "            print(\"System: \", system)\n",
    "            print(\"Prompt: \", prompt)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=th.get_tools(\"thp-system-design-assistant\"),\n",
    "        )\n",
    "\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        iters = 0\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        while tool_calls and len(tool_calls) > 0 and iters < MAX_ITERS:\n",
    "            if verbose or intermediate_output:\n",
    "                if content:\n",
    "                    print(f\"Cycle {iters}: \", content)\n",
    "                else:\n",
    "                    print(f\"Cycle {iters}: No content.\")\n",
    "            messages += th.run_tools(response)\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=th.get_tools(\"thp-system-design-assistant\"),\n",
    "            )\n",
    "            if verbose or intermediate_output:\n",
    "                print(f\"Generated intermediate response...\")\n",
    "            content = response.choices[0].message.content\n",
    "            iters += 1\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "        if content and (verbose or intermediate_output):\n",
    "            print(f\"Final response: {content}\")\n",
    "\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return \"Sorry, failed to generate response.\\nError: \" + str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: System Design Report Generation on \"Bloom Filters\" with OpenAI and Toolhouse\n",
    "\n",
    "This code demonstrates the generation of a system design report on a specified topic, in this case, **\"Bloom Filters\"**, using OpenAI's language model and Toolhouse API. Additionally, the report is sent via email to a specified recipient.\n",
    "\n",
    "---\n",
    "\n",
    "#### Topic Selection & Email Configuration:\n",
    "\n",
    "- **Topic:**  \n",
    "  The topic is set to **\"Bloom Filters\"**, guiding the AI to focus on explaining the concept.\n",
    "  \n",
    "- **Recipient Email:**  \n",
    "  The generated report will be sent to **\"contact.adityapatange@gmail.com\"**.\n",
    "\n",
    "#### System Message Setup:\n",
    "\n",
    "- A system message is created to define the role and expectations of the AI:\n",
    "  - `\"You are THP System Design AI\"` â€“ The AI is positioned as a system design assistant.\n",
    "  - `\"An intelligent assistant that helps you understand system design concepts\"` â€“ The assistantâ€™s role is further clarified, focusing on system design concepts.\n",
    "  - `\"You will provide detailed explanations of the topics you are asked to research\"` â€“ The assistant is tasked with providing in-depth content on the requested topic.\n",
    "  - `\"I will tell you the various things to research\"` â€“ Ensures the AI is prepared to handle structured research instructions.\n",
    "\n",
    "---\n",
    "\n",
    "#### Prompt Construction:\n",
    "\n",
    "- The prompt specifies the requirements for the system design report that the AI must generate:\n",
    "  - **Detailed Explanation:** The AI is instructed to explain the topic in detail, including its workings, use cases, advantages, disadvantages, and industry examples.\n",
    "  - **Markdown Report:** The output must be in Markdown format, useful for study purposes.\n",
    "  - **Email Formatting:** The AI formats the explanation as an HTML email with the title **\"The Hackers Playbook System Design: Case Studies on Bloom Filters\"**.\n",
    "  - **Email Sending:** The final report must be sent to the provided email address.\n",
    "\n",
    "---\n",
    "\n",
    "#### LLM Function Execution:\n",
    "\n",
    "- The core function **`llm()`** integrates OpenAIâ€™s LLM calls with Toolhouse tools, handling the report generation and sending of the email:\n",
    "  - **Initial Call:** Sends the constructed prompt to OpenAIâ€™s GPT model (gpt-4o) with the system design assistant tools.\n",
    "  - **Toolhouse Integration:** Enhances AI capabilities using Toolhouse tools like SendGrid (for sending emails), memory (for persisting information), and web scraping (for fetching related data).\n",
    "  - **Iterations:** Iterative tool calls ensure the content is refined until the final output is obtained, with a cap on iterations (MAX_ITERS).\n",
    "  - **Intermediate Outputs:** With the **verbose** flag enabled, intermediate results are printed to allow real-time monitoring of progress.\n",
    "\n",
    "---\n",
    "\n",
    "#### Email Sending:\n",
    "\n",
    "- After processing, the AI formats the detailed report into an HTML email.\n",
    "- The email is dispatched to the specified address using **SendGrid** integrated into the Toolhouse bundle.\n",
    "\n",
    "---\n",
    "\n",
    "### What Happens in the Code:\n",
    "\n",
    "1. **Setting Up Variables:**  \n",
    "   The **topic** and **email** are defined to provide context for the AI's task.\n",
    "\n",
    "2. **System and Prompt Setup:**  \n",
    "   The **system message** defines the assistantâ€™s role, and the **prompt** is constructed to request a detailed explanation of the topic, including markdown formatting and email dispatch instructions.\n",
    "\n",
    "3. **LLM Function Call:**  \n",
    "   The **llm()** function is called with the constructed prompt and system settings. The AI processes the task using the OpenAI model and Toolhouse tools.\n",
    "\n",
    "4. **Result Processing:**  \n",
    "   The report is generated in markdown format, then converted into HTML for the email.\n",
    "\n",
    "5. **Email Dispatch:**  \n",
    "   The final HTML report is sent to the recipientâ€™s email address.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing simple 'System Design' report emailer use case\n",
    "\n",
    "topic = \"Bloom Filters\"\n",
    "email = \"contact.adityapatange@gmail.com\"\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "system = f\"\"\"\n",
    "    You are THP System Design AI.\n",
    "    An intelligent assistant that helps you understand system design concepts.\n",
    "    You will provide detailed explanations of the topics you are asked to research.\n",
    "    I will tell you the various things to research. \n",
    "    You will generate a detailed markdown report on the topic.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "    Provide a detailed explanation of {topic}.\n",
    "    Include the following points:\n",
    "    - What is {topic}?\n",
    "    - How does '{topic}' work?\n",
    "    - What are the use cases of '{topic}'?\n",
    "    - Advantages and disadvantages of '{topic}'. (If applicable)\n",
    "    - Industry examples of {topic}. \n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    - Generate a detailed markdown report on {topic}.\n",
    "    This is for study purposes, so please provide a detailed explanation.\n",
    "    - Generated a nicely formatted HTML email on your research with title 'The Hackers Playbook System Design: Case Studies on {topic}'.\n",
    "    - Send the email to {email}\n",
    "\"\"\"\n",
    "\n",
    "response = llm(\n",
    "    prompt, model=model, system=system, intermediate_output=True, verbose=True\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This app serves as a powerful tool for automating **system design research** and **report generation** by leveraging OpenAIâ€™s language model and Toolhouseâ€™s suite of tools. With capabilities like **GPT-4 integration** and **email delivery through SendGrid**, the app efficiently generates detailed and structured reports on complex topics, such as **Bloom Filters**, and sends them directly to the userâ€™s email.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Strengths of the App:\n",
    "\n",
    "1. **Seamless Integration:**  \n",
    "\n",
    "   Combines the power of OpenAI and Toolhouse to create a robust environment for automated research and report delivery.\n",
    "\n",
    "2. **Customizable Functionality:**  \n",
    "\n",
    "   Users can easily modify the topic or focus area, enabling **flexible, on-demand research generation** tailored to specific needs.\n",
    "\n",
    "3. **Automated Workflow:**  \n",
    "\n",
    "   From generating detailed markdown reports to delivering formatted HTML emails, the app automates the entire process, saving time and effort.\n",
    "\n",
    "4. **Iterative Process:**  \n",
    "\n",
    "   Supports iterative tool calls to refine content until it meets the desired quality and level of detail.\n",
    "\n",
    "5. **Practical Use Cases:**  \n",
    "\n",
    "   Perfect for students, professionals, or teams involved in system design. It is useful for:\n",
    "\n",
    "   - Studying and exploring new concepts.\n",
    "   - Researching detailed system design topics.\n",
    "   - Generating professional reports with easy email sharing.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Thoughts:\n",
    "\n",
    "With its **flexibility**, **ease of use**, and **ability to deliver tailored insights**, this app is an invaluable resource for anyone looking to **explore or present system design concepts** in a structured, professional manner. It not only accelerates learning but also simplifies **knowledge sharing**, making it an efficient tool for study, research, and professional collaboration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! ðŸŒ\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
