{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Optimization and Evaluation with OpenAI API\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "## Description:\n",
    "\n",
    "This app utilizes OpenAI's GPT-4 model to optimize prompts and evaluate their effectiveness. The PromptOptimizer class refines a given prompt using instructions, iterating several times to improve clarity, conciseness, and effectiveness. After optimization, the app evaluates the original and optimized prompts to generate a comparison report with reasons and scores. The app can be used to optimize prompts for production environments, ensuring they are effective and clear for LLM usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installing Requirements  \n",
    "\n",
    "The code defines the install_requirements function to install packages from `requirements.txt` if they aren't already installed. It retries up to three times if the installation fails, exiting with an error if all attempts fail. This ensures the required dependencies are in place before continuing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "install_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting Up Environment Variables  \n",
    "\n",
    "The code loads environment variables using `load_dotenv()` to ensure sensitive information like API keys is available. \n",
    "\n",
    "It then checks if required variables, such as `OPENAI_API_KEY`, are set, prompting the user to set them if missing and exiting the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "    load_dotenv()\n",
    "\n",
    "    variables_to_check = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "setup_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prompt Optimization and Evaluation with OpenAI\n",
    "\n",
    "The PromptOptimizer class refines user prompts for OpenAI‚Äôs GPT-4 model by optimizing them for clarity and effectiveness over multiple iterations. \n",
    "\n",
    "It uses the OpenAI API to send the prompt with optimization instructions, refining it until the desired result is achieved. \n",
    "\n",
    "The optimize method runs the optimization process, while the get_optimized_prompt method retrieves the final version. \n",
    "\n",
    "The evaluate method compares the original and optimized prompts, generating a markdown report with a detailed comparison. \n",
    "\n",
    "This class ensures the prompt is concise, clear, and production-ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "class PromptOptimizer:\n",
    "    \"\"\"A simple prompt optimization class that uses OpenAI's Chat API to optimize prompts.\"\"\"\n",
    "\n",
    "    def __init__(self, prompt: str):\n",
    "        \"\"\"Initializes the PromptOptimizer with the given prompt. \"\"\"\n",
    "        self.ai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.prompt = prompt\n",
    "        self.optimized_prompt = None\n",
    "\n",
    "    def optimize(self, optimize_instructions = [\n",
    "        \"Refine the given prompt so that it is fit for use in production environments.\",\n",
    "        \"Make the prompt concise, detailed and clear with a good balance of effectivenss and usefulness.\",\n",
    "    ], turns = 3) -> str:\n",
    "        \"\"\"Optimizes the prompt based on optimize instructions.¬†\"\"\"\n",
    "\n",
    "        prompt_to_optimize = self.prompt\n",
    "        previous_optimized_prompt = prompt_to_optimize\n",
    "        for i in range(turns):\n",
    "            try:\n",
    "                print(f\"Optimizing prompt - Turn {i+1}...\")\n",
    "                optimize_prompt = f\"\"\"\n",
    "                    You will be given a prompt, refine it as per the given instructions. \n",
    "                    In addition to the instructions, come up with improvements and apply the refinements to the prompt.\n",
    "                    Respond only with the final refined prompt after all improvements are made.\n",
    "                    Instructions: ```{\"\\n\".join(optimize_instructions)}```\n",
    "                    Prompt: {previous_optimized_prompt}\n",
    "                \"\"\"\n",
    "                system = \"You are an AI prompt optimizer with deep understanding of LLM technology.\"\n",
    "                ai_response = self.ai.chat.completions.create(\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system},\n",
    "                        { \"role\": \"user\", \"content\": optimize_prompt }\n",
    "                    ],\n",
    "                    model=\"gpt-4o-mini\"\n",
    "                )\n",
    "                previous_optimized_prompt = ai_response.choices[0].message.content\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to optimize prompt for turn {i+1}: {e}\")\n",
    "                continue\n",
    "        self.optimized_prompt = previous_optimized_prompt\n",
    "        return self.optimized_prompt\n",
    "    \n",
    "    def get_optimized_prompt(self) -> str:\n",
    "        \"\"\"Returns the optimized prompt.\"\"\"\n",
    "        if not self.optimized_prompt:\n",
    "            optimized_prompt = self.optimize()\n",
    "            if not optimized_prompt:\n",
    "                print(\"Failed to optimize the prompt.\")\n",
    "        return self.optimized_prompt\n",
    "    \n",
    "\n",
    "    def evaluate(self):\n",
    "        try:\n",
    "            print(\"Evaluating the optimized prompt...\")\n",
    "            optimized_prompt = self.get_optimized_prompt()\n",
    "\n",
    "            if not optimized_prompt:\n",
    "                print(\"Failed to get the optimized prompt, can't evaluate.\")\n",
    "                return None\n",
    "            \n",
    "            evaluation_prompt = f\"\"\"\n",
    "                    Given two prompts, compare the original prompt and the optimized prompt. \n",
    "                    Provide a table with the comparison of the two prompts along with reasons and scores.\n",
    "                    In the markdown response provide a title, summary, and conclusion and the table. \n",
    "                    Respond in markdown format strictly. \n",
    "                    Make sure the markdown tables are compatible with Jupyter notebooks.\n",
    "                    Original Prompt: {self.prompt}\n",
    "                    Optimized Prompt: {optimized_prompt}\n",
    "                \"\"\"\n",
    "            \n",
    "            response = self.ai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are expert in prompt evaluation.\"},\n",
    "                    {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "                ])\n",
    "            \n",
    "            header = f\"\"\"# Prompt Optimization Report\\n## Original Prompt\\n{self.prompt}\\n## Optimized Prompt\\n{self.optimized_prompt}\"\"\"\n",
    "            report = response.choices[0].message.content\n",
    "            full_report = header + report\n",
    "            return full_report\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to evaluate the optimized prompt: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Prompt Optimization and Generate Evaluation Report\n",
    "\n",
    "The run_prompt_optimizer function optimizes a given prompt using the PromptOptimizer class and generates an evaluation report.\n",
    "\n",
    " It creates an instance of the PromptOptimizer with the provided prompt, calls get_optimized_prompt() to retrieve the optimized prompt, and clears the notebook output for a clean display. \n",
    " \n",
    " It then evaluates the original and optimized prompts using evaluate() and returns the evaluation report in Markdown format for proper rendering in Jupyter notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Markdown\n",
    "\n",
    "def run_prompt_optimizer(prompt: str) -> None:\n",
    "    prompt_optimizer = PromptOptimizer(prompt)\n",
    "    optimized_prompt = prompt_optimizer.get_optimized_prompt()\n",
    "    clear_output()\n",
    "    report = prompt_optimizer.evaluate()\n",
    "    return Markdown(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Prompt Optimization and Evaluation\n",
    "\n",
    "### Example 1:\n",
    "\n",
    "The prompt asks for a detailed plan for learning Python programming in 2025.\n",
    "\n",
    "`run_prompt_optimizer(prompt)` will optimize this prompt and generate an evaluation report comparing the original and optimized versions.\n",
    "\n",
    "### Example 2:\n",
    "\n",
    "The prompt asks for the Standard Operating Procedure (SOP) for a conflict resolution strategy for a team of 5 members in a Big 4 firm.\n",
    "\n",
    "`run_prompt_optimizer(prompt)` will optimize this prompt and provide an evaluation report as well.\n",
    "\n",
    "In both examples, the function optimizes and evaluates the prompts using the `PromptOptimizer` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "\n",
    "prompt = \"Give me a detailed plan for learning Python Programming in 2025.\"\n",
    "\n",
    "run_prompt_optimizer(prompt)\n",
    "\n",
    "# Example 2\n",
    "\n",
    "prompt = \"Give me the SOP of a conflict resolution strategy for a team of 5 members in a Big 4 Firm.\"\n",
    "\n",
    "run_prompt_optimizer(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "This app provides an easy-to-use interface for refining prompts and evaluating their effectiveness in AI-driven environments. By using OpenAI's GPT-4 model, the app ensures that prompts are optimized to be concise, clear, and useful, followed by a detailed evaluation report comparing the original and optimized prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! üåê\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
