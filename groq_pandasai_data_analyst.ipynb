{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Exploratory Data Analyst üìä\n",
    "\n",
    "##### üí° **Research Areas:** Rapid Prototyping, Generative AI, Exploratory Data Analysis, Question-Answering Systems.\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"300px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "An AI data analyst that performs **Exploratory Data Analysis** on a dataset using question-answering model with LLMs.\n",
    "\n",
    "The goal of this prototype is to demonstrate the automation of Data Analytics Activity, highlight use-cases for Pandas AI, and experiment with Question-Answer type models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing Dependencies\n",
    "\n",
    "- `os`\n",
    "Accesses environment variables and file paths.\n",
    "\n",
    "- `pandas as pd`\n",
    "Loads and manipulates data in tabular format.\n",
    "\n",
    "- `load_dotenv`\n",
    "Loads API keys securely from a `.env` file.\n",
    "\n",
    "- `typing (List, Union)`\n",
    "Provides type annotations.\n",
    "\n",
    "- `SmartDataframe, SmartDatalake`\n",
    "Adds AI-driven querying to Pandas.\n",
    "\n",
    "- `OpenAI`\n",
    "Enables natural language queries with OpenAI models.\n",
    "\n",
    "- `BaseModel`\n",
    "Ensures structured data validation.\n",
    "\n",
    "- `Groq`\n",
    "Connects to Groq AI for generating responses.\n",
    "\n",
    "- `instructor`\n",
    "Manages AI query execution efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Installing Requirements\n",
    "\n",
    "The `install_requirements()` function ensures the environment is set up by installing dependencies from a requirements.txt file. It checks if dependencies are already installed to avoid redundancy and attempts installation up to three times if it fails. This guarantees that all necessary packages are available for the application to run smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "install_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setting Up Environment Variables\n",
    "\n",
    "This script loads and checks essential environment variables needed for the application. It uses `load_dotenv()` to load variables from the `.env` file, ensuring that any existing variables are overwritten. The `check_env()` function checks if each required variable (`GROQ_API_KEY`, `OPENAI_API_KEY`, `PANDASAI_API_KEY`) is set in the environment, and if not, the script exits with an error message. If all variables are set, the script confirms they are properly loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    variables_to_check = [\"GROQ_API_KEY\", \"OPENAI_API_KEY\", \"PANDASAI_API_KEY\"]\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "        \n",
    "setup_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Groq Client Setup\n",
    "\n",
    "This setup initializes a Groq AI client using an API key from environment variables.\n",
    "\n",
    "\n",
    "- `get_groq_client()`: Creates and returns a Groq client using instructor with JSON mode.\n",
    "\n",
    "- `llm(prompt, response_model, system, model)`: Sends a user query to the Groq model, formats responses per `response_model`, and returns results.\n",
    "\n",
    "- `Error Handling`: Catches exceptions, prints errors, and returns an `LLMErrorResponse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from groq import Groq\n",
    "import traceback\n",
    "from pydantic import BaseModel\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "def get_groq_client():\n",
    "    \"\"\"Returns an instance of the Groq class\"\"\"\n",
    "    groq = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "    client = instructor.from_groq(groq, mode=instructor.Mode.JSON)\n",
    "    return client\n",
    "\n",
    "\n",
    "def llm(\n",
    "    prompt: str,\n",
    "    response_model: BaseModel,\n",
    "    system=\"You are a helpful AI assistant. The user will talk to you and its your job to provide detailed and clear responses.\",\n",
    "    model=DEFAULT_MODEL,\n",
    ") -> Union[BaseModel, LLMErrorResponse]:\n",
    "    \"\"\"Calls LLM API with the given prompt. Defaults to llama-3.3-70b-versatile\"\"\",\n",
    "    try:\n",
    "        client = get_groq_client()\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            messages=messages, model=model, response_model=response_model\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return LLMErrorResponse(error=str(e))\n",
    "    \n",
    "setup_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Dataset Querying and Analysis System\n",
    "\n",
    "This code defines a class structure to load, manage, and query datasets, using an LLM to provide insights from data.\n",
    "\n",
    "\n",
    "- The `Dataset` class initializes by loading tables from CSV files into a `SmartDataframe` and `SmartDatalake`. It uses the `OpenAI` API to facilitate querying the data with natural language.\n",
    "\n",
    "- The `ask()` method lets you query the dataset, processes the response, and formats it according to the specified format (markdown by default).\n",
    "\n",
    "- The `BooksDataset` and `StudentPerformanceDataset` classes are subclasses of `Dataset`, pre-configured for specific datasets, such as books or student performance.\n",
    "\n",
    "- The `SmartDataframe` and `SmartDatalake` are used to enhance the data with AI capabilities for more insightful querying.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from typing import List\n",
    "from pandasai import SmartDataframe, SmartDatalake\n",
    "from pandasai.llm import OpenAI\n",
    "\n",
    "\n",
    "class FormattedLLMResponse(BaseModel):\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"Dataset class which contains tables corresponding to CSV files in the base folder\"\"\"\n",
    "\n",
    "    def __init__(self, database: str, tables: List[str]):\n",
    "        llm = OpenAI(api_token=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        if len(tables) == 0:\n",
    "            raise ValueError(\"Tables list cannot be empty.\")\n",
    "\n",
    "        if not os.path.isdir(f\"data/{database}\"):\n",
    "            raise FileNotFoundError(f\"Directory {database} not found.\")\n",
    "\n",
    "        self.base_path = os.path.join(os.getcwd() + \"/data\", database)\n",
    "        self.tables = {}\n",
    "        self.dataframes = {}\n",
    "\n",
    "        for table in tables:\n",
    "            table_file_path = os.path.join(self.base_path, f\"{table}.csv\")\n",
    "            if not os.path.isfile(table_file_path):\n",
    "                print(f\"Table file {table_file_path} not found. Skipping. \")\n",
    "                continue\n",
    "            df = pd.read_csv(table_file_path)\n",
    "            self.tables[table] = SmartDataframe(df)\n",
    "            self.dataframes[table] = pd.read_csv(table_file_path)\n",
    "\n",
    "        print(f\"Loaded {len(self.tables)} tables from {database} dataset.\")\n",
    "\n",
    "        self.datalake = SmartDatalake(\n",
    "            [self.tables[key] for key in self.tables.keys()], config={\"llm\": llm}\n",
    "        )\n",
    "\n",
    "    def get_table(self, table_name: str) -> SmartDataframe:\n",
    "        table = self.tables.get(table_name)\n",
    "        if table is None:\n",
    "            raise ValueError(f\"Table {table_name} not found.\")\n",
    "        return table\n",
    "\n",
    "    def get_datalake(self) -> SmartDatalake:\n",
    "        return self.datalake\n",
    "\n",
    "    def ask(self, query: str, format=\"markdown\") -> str:\n",
    "        print(\"Asking...\")\n",
    "        datalake = self.get_datalake()\n",
    "        df = datalake.chat(query)\n",
    "        print(\"Asked.\")\n",
    "        df_string = \"\"\n",
    "        if type(df) == str:\n",
    "            df_string = df\n",
    "        elif type(df) == pd.DataFrame:\n",
    "            df_top = df.head(10)\n",
    "            df_string = str(df_top)\n",
    "        prompt = f\"\"\"\n",
    "            Query: {query}\n",
    "            Database Result: {df_string}\n",
    "            Instructions:\n",
    "            - Format the data and provide a human readable summary.\n",
    "            - Provide insights and recommendations.\n",
    "            - Don't hallucinate or make up data.\n",
    "            - Provide clear, detailed and concise responses.\n",
    "            f\"The 'response' field should be of format = '{format}'\" if format == \"markdown\" else \"\"\n",
    "        \"\"\"\n",
    "        llm_response = llm(prompt, response_model=FormattedLLMResponse)\n",
    "        return llm_response.response\n",
    "\n",
    "\n",
    "class BooksDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"books\", [\"books\", \"ratings\", \"users\"])\n",
    "\n",
    "\n",
    "class StudentPeformanceDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"student_performance\", [\"student_performance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Render Markdown Output\n",
    "\n",
    "This function, `render_output()`, takes a string containing markdown content and displays it as rendered Markdown in an IPython environment (e.g., Jupyter Notebook).\n",
    "\n",
    "- It uses `Markdown` from `IPython.display` to convert the markdown text into a formatted output.\n",
    "\n",
    "- This allows you to visualize the results of queries or insights in a human-readable markdown format within the notebook.\n",
    "\n",
    "The function doesn't return a value; it just renders the formatted markdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def render_output(markdown: str) -> None:\n",
    "    \"\"\"Renders the generated output file as markdown.\"\"\"\n",
    "    return Markdown(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Querying Dataset and Displaying the Result\n",
    "\n",
    "The ask_query function allows interactive querying of a dataset, ensuring clear and formatted output in a Jupyter notebook.\n",
    "\n",
    "\n",
    "- The function takes a `query` and a `dataset` as input. It calls the `ask()` method from the dataset to get the query's response.\n",
    "\n",
    "- `clear_output()` ensures the output area is cleared before showing the new response.\n",
    "\n",
    "- The response is formatted by adding the query as a heading and is passed to the `render_output()` function to display the formatted result as Markdown in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def ask_query(query: str, dataset: Dataset) -> None:\n",
    "    \"\"\"Asks the given query to the dataset and returns the response.\"\"\"\n",
    "    response = dataset.ask(query)\n",
    "    clear_output()\n",
    "    response = f\"### Query: {query}\\n{response}\"\n",
    "    return render_output(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Query Execution on Books and Student Performance\n",
    "\n",
    "`ask_query_on_books` & `ask_query_on_student_performance`:\n",
    "\n",
    "- Specialized functions that initialize the respective dataset objects and query the data using the ask_query method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_query_on_books(query: str) -> None:\n",
    "    \"\"\"Main function to run the script\"\"\"\n",
    "    books_dataset = BooksDataset()\n",
    "    return ask_query(query, books_dataset)\n",
    "\n",
    "\n",
    "def ask_query_on_student_performance(query: str) -> None:\n",
    "    \"\"\"Main function to run the script\"\"\"\n",
    "    student_performance_dataset = StudentPeformanceDataset()\n",
    "    return ask_query(query, student_performance_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Running Queries\n",
    "- Sample Queries:\n",
    "\n",
    "    - Queries for top 10 books with highest average ratings and top 10 students with highest average grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the top 10 books with the highest average rating?\"\n",
    "\n",
    "ask_query_on_books(query)\n",
    "\n",
    "query = \"What are the top 10 students with the highest average grades?\"\n",
    "\n",
    "ask_query_on_student_performance(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: DataAnalysisAgent Class\n",
    "\n",
    "- Handles data analysis by asking a series of predefined questions and aggregating the answers into a business report.\n",
    "- `analyse` method: Asks predefined questions, compiles answers, and generates a report using LLM.\n",
    "\n",
    "- `get_analysis` method: Returns the analysis, either generated or cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class BusinessReport(BaseModel):\n",
    "    markdown: str\n",
    "\n",
    "\n",
    "class DataAnalysisAgent:\n",
    "    def __init__(self, dataset: Dataset):\n",
    "        self.dataset = dataset\n",
    "        self.analysis = None\n",
    "\n",
    "    def analyse(self) -> str:\n",
    "        # instruction = \"Respond in a human readable format. Don't provide graphs or execute code.\"\n",
    "        analysis_questions = [\n",
    "            \"What are the key insights from the dataset?\",\n",
    "            \"What are the key trends in the dataset?\",\n",
    "            \"What are the key patterns in the dataset?\",\n",
    "            \"What are the key anomalies in the dataset?\",\n",
    "            \"What are the key recommendations based on the dataset?\",\n",
    "        ]\n",
    "        self.analysis = \"\"\n",
    "        for question in analysis_questions:\n",
    "            try:\n",
    "                answer = self.dataset.ask(question)\n",
    "                self.analysis += f\"\\n### üëâüèΩ {question}\\nüí° {answer}\"\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to ask question: {question}\")\n",
    "                # print(e)\n",
    "                continue\n",
    "        print(\"Preliminary analysis completed. Generating business report...\")\n",
    "        prompt = f\"\"\"\n",
    "            Understand the provided analysis for the dataset and provide a neatly formatted report.\n",
    "            This report should be professional, detailed and ideal for business stakeholders.\n",
    "            The report should include all facts in the preliminary analysis and provide additional insights.\n",
    "            The 'response' field should be of format = 'markdown'\n",
    "\n",
    "            Preliminary Analysis: {self.analysis}\n",
    "        \"\"\"\n",
    "        llm_response = llm(prompt=prompt, response_model=BusinessReport)\n",
    "        if not llm_response:\n",
    "            print(\"Failed to get response from LLM.\")\n",
    "            return self.analysis\n",
    "        self.analysis = llm_response.markdown\n",
    "        print(\"Business report generated.\")\n",
    "        return self.analysis\n",
    "\n",
    "    def get_analysis(self) -> str:\n",
    "        if self.analysis is None:\n",
    "            return self.analyse()\n",
    "        return self.analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Data Analysis Execution\n",
    "- `data_analysis_on_books` & `data_analysis_on_student_performance`:\n",
    "\n",
    "    - Calls the DataAnalysisAgent on the respective datasets (Books and Student Performance) and renders the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Markdown\n",
    "\n",
    "\n",
    "def data_analysis(dataset: Dataset) -> Markdown:\n",
    "    agent = DataAnalysisAgent(dataset)\n",
    "    analysis = agent.analyse()\n",
    "    clear_output()\n",
    "    return render_output(analysis)\n",
    "\n",
    "\n",
    "def data_analysis_on_books() -> Markdown:\n",
    "    books_dataset = BooksDataset()\n",
    "    return data_analysis(books_dataset)\n",
    "\n",
    "\n",
    "def data_analysis_on_student_performance() -> Markdown:\n",
    "    student_performance_dataset = StudentPeformanceDataset()\n",
    "    return data_analysis(student_performance_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Triggering the Data Analysis:\n",
    "\n",
    "- Calls data analysis on both the student performance and books datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analysis_on_student_performance()\n",
    "data_analysis_on_books()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! üåê\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
